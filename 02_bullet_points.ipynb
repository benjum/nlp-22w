{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb19159-d973-4eee-8acf-055858042908",
   "metadata": {},
   "source": [
    "# Identify a text's bullet point sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059df828-3b31-416d-9bd9-fbf36ae3599e",
   "metadata": {},
   "source": [
    "Let's say we only want to share the important parts of an article we've read, or that we have lots of journal articles to read but not enough time, so we only want to read the highlights.\n",
    "\n",
    "* Auto-generate the bullet points\n",
    "  * Find most important words\n",
    "  * Assign score to sentences based on their words\n",
    "  * Output the top-scoring sentences\n",
    "\n",
    "To do this we need to know how to:\n",
    "* identify word importance\n",
    "  * authors tend to repeat important words -> use word frequency\n",
    "* assign score to sentences\n",
    "  * take the words it contains and sum their \"importances\"\n",
    "* output top scorers\n",
    "  * rank the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8eed3-a41b-4718-a61a-539005733edc",
   "metadata": {},
   "source": [
    "## First Steps:\n",
    "* get text (scrape data)\n",
    "* munge text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926c885-87a6-4ac9-991c-d99e6bccd21e",
   "metadata": {},
   "source": [
    "What does \"munge\" mean?  Let's make our own dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2231a92-f604-4151-84fa-bd4aa379f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51ebd5-25b8-4672-ac80-8453e0d6f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bendict(word):\n",
    "    for ss in wordnet.synsets(word):\n",
    "        print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb9ecc-77f5-4acf-822c-1f937c2b369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bendict('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94855d-d063-412c-b469-1d8d060ef9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bendict('coding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491302e-4e74-4fc0-9c8a-b862113a14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bendict('munge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50ff45-6dc3-4e1d-a683-be3ea013ba51",
   "metadata": {},
   "source": [
    "Ah well, there are shortcomings to the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d9883-5842-4678-932c-0358ea23f5d6",
   "metadata": {},
   "source": [
    "## Retrieve an interesting article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5d10c-f529-4df0-a7ed-2f655e675fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3c53a-f3f4-4d92-9108-6e5b7ad457d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/'\n",
    "response = requests.get(url)\n",
    "document = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0f2ac-6d51-4f96-866b-186592e781d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e3760-8f61-4327-b167-0b1acc97c7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "humtext = document.find('div', attrs={'class':'entry-content'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f95d1a-a097-43bd-99be-e9dbf52b2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['\\n','[',']','’','”','“']:\n",
    "    humtext = humtext.replace(i,' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826b6e4-6ef8-4edc-841d-fc29ce1540fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(humtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17911d-d1a0-4d11-acd3-aaa64c271e36",
   "metadata": {},
   "source": [
    "## Process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70bf1b-55a2-4aab-92c0-1a07e8eb885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e2e55-1257-44a8-bc18-03bd21babb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(humtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472dd18-f91e-4358-a818-37e6fe397c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87694ee0-dac1-401c-bd22-0d33fde63747",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(humtext.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d3ab4-6366-4dec-9264-78e0154075e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48ba93-524e-4362-9d9e-fdbbbc25d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStopWords = list(punctuation) + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9998f0d-6e66-4346-b579-59c8217a1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsNoStopWords = [w for w in words if w not in myStopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cf5cd-5b59-439e-87af-2426a611fb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordsNoStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f66294-5d90-4551-b1a4-deeb6d511b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff914e7-9239-499f-892b-a27dfcff60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = FreqDist(wordsNoStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c7449-4c3f-403a-b658-3b3c30d84c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d1910-d1bd-4e94-8895-8f52931b45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(freq, key=freq.get, reverse=True)[:10]:\n",
    "    print(i,freq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b15f0-6328-48d6-9155-3befdff48087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranking = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    ranking[sentence] = 0\n",
    "    for word in word_tokenize(sentence.lower()):\n",
    "        if word in freq:\n",
    "            ranking[sentence] += freq[word]\n",
    "            \n",
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485039e-85a3-4f31-bac2-f7d197e05bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(ranking, key=ranking.get, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a3f4b-917d-452f-aa18-1d012bd09156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    if sentence in sorted(ranking, key=ranking.get, reverse=True)[:5]:\n",
    "        print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
